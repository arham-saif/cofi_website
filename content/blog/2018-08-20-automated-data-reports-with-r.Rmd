---
title: Automated Data Reports with R
author: Paul Campbell
description: "Create reproducible reports from data cleaning to visualisation with rmarkdown"
date: '2018-08-20'
slug: automated-data-reports-with-r
twitterImg: img/party_points_small.png
categories:
  - Tutorials
tags:
  - R
  - rmarkdown
  - data reporting
  - data visualisation
  - ggplot2
draft: true
params:
  continent: Europe
---

A lot of data analysts will find themselves doing repetitive manual tasks on a data set every day/week/month in Excel, then copying and pasting their updated pivot tables and charts into Word or PowerPoint reports for their stakeholders. If this sounds like your job description, you may want to consider switching to a programming language like R. Writing scripts will allow you to automate the majority of these processes; from importing your data all the way through to emailing your boss the final report. They'll never know you were actually in the pub the whole time.

Automation may sound like a scary word to any human being with a job that would like to keep it, but learning to automate some of your most common data tasks can be seriously beneficial to both your organisation and your own job security! Some of the benefits of an automated reporting workflow over a manual one include:

1. **It saves you time.** Most people will feel like they don't have the time they need to fulfill all that is asked of them at work. So if you can cut out the time taken on manual data processing and focus more analysis and insight, that can only be a good thing.
2. **It reduces errors.** When your reporting relies on manual data entry and formula with hard-coded cell references, one typo or out-of-place number can lead to results that are way off the mark. Automating the process with a script will remove the possibility of human error completely.
3. **It expands your data visualisation options.** Using an open-source software like R will allow to draw on a vast array of tools and charting libraries not available in proprietary software. For example, HTML reports with the <a href="https://rmarkdown.rstudio.com/" target="_blank">rmarkdown</a> package can include interactive charts, maps and tables that utilise the latest web-technologies - more on this below.

---

## Worked Example

In this post we're going to run through what might be a typical workflow of building a reproducible data report in R - that is, one that you can simply hit 'Run' on whenever a new wave of data comes in, and all your charts and tables update accordingly giving you the latest insights in your data at the touch of a button.

I'm going to use the classic gapminder dataset that contains population, life expectancy, and GDP per capita metrics for many countries over time. There is a gapminder R package that would conveniently give us the data in a format best suited for data analysis - <a href="https://en.wikipedia.org/wiki/Tidy_data" target="_blank">tidy data</a> - but we want to make this run-through as realistic as possible. 

As such, I've taken this tidy data set, removed one of the variables that we'll have to add ourselves later, then split it up by year across multiple excel sheets in a single excel file. Sacrilige, I know, but from experience this is a very common way data with multiple time periods is stored and distributed, so it will be useful to know how to bring it back together again with R code. If you're interested in the code required to commit such a heinous crime of 'untidying' a data set into excel sheets you can check out the <a href="https://gist.github.com/PaulC91/a3c61cee7bcdef7bba31d675bfa726eb" target="_blank">make gapminder messy again</a> R script over on github.

<iframe width="100%" height="500px" frameborder="no" src="https://view.officeapps.live.com/op/view.aspx?src=https%3A%2F%2Fwww.cultureofinsight.com%2Fdata%2Fgapminder_messy.xlsx"></iframe>

As you can see from the Excel file, each tab contains data for the year denoted in the tab name. Here we have 5 year intervals between data but in a more realistic scenario these would be daily, weekly or monthly updates for which this process would work equally well. Similarly, if the data was seperated by a different type of variable such as survey results for different demographic target groups, the process below would allow you to combine the data and visualise the differences between the demographics. 

So let's begin with the code! If you're brand new to R don't worry if you don't know the ins and outs of the syntax. Hopefully you will see that we can get a lot done with not a lot of code!

---

```{r include=FALSE}
knitr::opts_chunk$set(fig.retina = 2,
                      fig.width = 10, 
                      fig.height = 7,
                      fig.align = "center", 
                      cache = FALSE,
                      message=FALSE, 
                      warning=FALSE, 
                      echo=TRUE
                      )
```

## Load the Libraries

First thing first is to load the libraries we'll be using for our report and set a default ggplot2 chart theme.

```{r setup, cache=FALSE}
library(tidyverse)
library(readxl)
library(scales)
library(countrycode)
library(hrbrthemes)
library(gghighlight)
library(gganimate)
library(glue)
library(plotly)
library(formattable)
library(DT)
library(widgetframe)
library(crosstalk)

theme_set(theme_ft_rc())
```

---

## Data Importing & Tidying

This is the part that can be most satisfying to automate because the manual equivalent is often very tedious, time-consuming work. We're going to program a process that will:

- iterate over each sheet in the excel file
- pull out only the data table section (starting on row 5)
- add a `year` column populated by the name of the sheet
- combine all the seperate tables into one single data frame
- re-order the columns to our desired specifications

The reproducibility of this code comes from the fact that it is agnostic to the number of sheets in our excel file. That means whenever we get an updated file with a new tab of data, we just point the same code to this file and we'll get a new dataset that includes this new data. Any future computations we draw from the data such as latest period-on-period changes will automatically be derived from the latest available data that we have just received. 

```{r cache=TRUE}
path <- "../../data/blog_data/gapminder_messy.xlsx"

combined_data <- 
  excel_sheets(path) %>% 
  map_df(~ {
    read_excel(path, sheet = .x, skip = 4, trim_ws = TRUE) %>% 
      mutate(year = as.numeric(.x))
  }) %>% 
  select(country, year, everything())
```

Let's quickly inspect our data to check that it got it the job done...

```{r}
# top 6 rows
head(combined_data)

# bottom 6 rows
tail(combined_data)
```

Looking good. However part of our analysis is going to involve computing continental summary statistics, but we currently don't have a continent column in our dataset. Adding one in Excel would require us making our own lookup table with a corresponding continent for each unique country in the dataset then using a `VLOOKUP` function. 

In R we can easily make this part of the automated workflow using the `countrycode` package to translate from one geographical coding scheme to another - in our case getting a continent name based on a country name, like so:

```{r}
combined_data <- combined_data %>% 
  mutate(continent = countrycode(sourcevar = country, origin = "country.name", destination = "continent")) %>% 
  select(continent, everything())

head(combined_data)
```

---

## Paramaterising Your Report

We now have a consolidated dataset with an added continent variable coded to each country. A common case with data reporting would be to produce distinct reports from multiple subsets of a single data set. This is made easy using `rmarkdown` with the ability to supply a parameter at the top of your report script which can then be used as a variable in the code within the report to alter the outputs.

Let's say in our example we want to batch produce a report for each continent. If we supply the name of the continent we want to build the report for in the `params` section of what is known as the `YAML` at the top of the report script like so:

```
---
title: My Report
output: html_document
params:
   continent: Europe
---
```

We can then use that parameter to filter our consolidated data set to only countries matching the continent parameter and then use that data for all subsequent analysis.

```{r}
filtered_data <- combined_data %>% 
  filter(continent == params$continent)
```

Once we have our full report script ready to be executed, all we have to do to get a report from one continent to the next is change the value of the continent param at the top of the script. 

Or if we're being really clever about it, we can turn our report rendering call into an R function and pass it to a `purrr::walk` call that will iterate over each continent, render the report for each, then save the appropriately named time-stamped files to a directory of your choosing ready to be shared with all relevant stake holders:

```{r eval=FALSE}
continents <- c("Asia", "Europe", "Africa", "Americas", "Oceania")

renderMyReport <- function(continent) {
  rmarkdown::render("MyReport.Rmd", output_file = glue("{continent}_report_{Sys.Date()}.html"), 
                    params = list(continent = continent))
}

purrr::walk(continents, ~ renderMyReport)
```

But before we do that we need to code out the basis of the analysis we want contained our reports! So here are a few examples of the type of data visualisations that would help a stakeholder understand the latest metrics and insights from the data.

---

## Linked Interactive Graphics

In an HTML report, we can use linked interactive graphics to encourage users to engage with the data and explore the insights. Let's build some charts to show the latest period percentage changes of all 3 metrics in the data set. 

First we do the data wrangling to compute the changes...

```{r}

p_change <- filtered_data %>% 
  mutate(year = as.Date(glue("{year}-01-01"))) %>% 
  group_by(continent, country) %>% 
  arrange(year) %>% 
  mutate(gdpPercap_change = (gdpPercap - lag(gdpPercap)) / lag(gdpPercap),
         lifeExp_change = (lifeExp - lag(lifeExp)) / lag(lifeExp),
         pop_change = (pop - lag(pop)) / lag(pop))
         
latest_figs <- p_change %>% 
  filter(year == max(year)) %>%
  select(-year) %>% 
  arrange(country) %>% 
  ungroup()

```

Then we build the charts and add the linked functionality.

```{r eval=FALSE}
# create a shared data source with the crosstalk package
sd <- SharedData$new(latest_figs, ~country, group = "Highlight a Country")

# build 3 static ggplot charts with the shared data
sd_gdp <- ggplot(sd, aes(reorder(country, -gdpPercap_change), gdpPercap_change,
                               text = glue::glue("{country}, {continent}: {percent(gdpPercap_change)}"))) +
  geom_col(aes(fill = continent)) +
  scale_y_percent() +
  labs(title = "GDP Per Capita % Change", y = "GDP per capita") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.major.x = element_blank())

sd_le <- ggplot(sd, aes(reorder(country, -lifeExp_change), lifeExp_change,
                               text = glue::glue("{country}, {continent}: {percent(lifeExp_change)}"))) +
  geom_col(aes(fill = continent)) +
  scale_y_percent() +
  labs(title = "Life Expectacy % Change", y = "Life Expectancy") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.major.x = element_blank())

sd_pop <- ggplot(sd, aes(reorder(country, -pop_change), pop_change,
                               text = glue::glue("{country}, {continent}: {percent(pop_change)}"))) +
  geom_col(aes(fill = continent)) +
  scale_y_percent() +
  labs(title = "Latest Period % Change", y = "Population") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.major.x = element_blank())

# make them interactive with plotly
sd_gdp_i <- ggplotly(sd_gdp, tooltip = "text")
sd_le_i <- ggplotly(sd_le, tooltip = "text")
sd_pop_i <- ggplotly(sd_pop, tooltip = "text")

# arrange them together
subplot(sd_gdp_i, sd_le_i, sd_pop_i, nrows = 3, titleY = TRUE) %>% 
  config(collaborate = FALSE, displaylogo = FALSE) %>% 
  hide_legend() %>% 
  highlight(selectize = TRUE, on = "plotly_click", off = "plotly_doubleclick") %>% 
  frameWidget(height = "600px")

```

Use the search bar to highlight a particular country across all 3 charts or click directly on one of the bars. Double clicking will deselect the highlighted country.

Colours represent the continent each country is part of.

```{r echo=FALSE}
# create a shared data source with the crosstalk package
sd <- SharedData$new(latest_figs, ~country, group = "Highlight a Country")

# build 3 static ggplot charts with the shared data
sd_gdp <- ggplot(sd, aes(reorder(country, -gdpPercap_change), gdpPercap_change,
                               text = glue("{country}, {continent}: {percent(gdpPercap_change)}"))) +
  geom_col(aes(fill = continent)) +
  scale_y_percent() +
  labs(title = "GDP Per Capita % Change", y = "GDP per capita") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.major.x = element_blank())

sd_le <- ggplot(sd, aes(reorder(country, -lifeExp_change), lifeExp_change,
                               text = glue("{country}, {continent}: {percent(lifeExp_change)}"))) +
  geom_col(aes(fill = continent)) +
  scale_y_percent() +
  labs(title = "Life Expectacy % Change", y = "Life Expectancy") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.major.x = element_blank())

sd_pop <- ggplot(sd, aes(reorder(country, -pop_change), pop_change,
                               text = glue("{country}, {continent}: {percent(pop_change)}"))) +
  geom_col(aes(fill = continent)) +
  scale_y_percent() +
  labs(title = "Latest Period % Change", y = "Population") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.grid.major.x = element_blank())

# make them interactive with plotly
sd_gdp_i <- ggplotly(sd_gdp, tooltip = "text")
sd_le_i <- ggplotly(sd_le, tooltip = "text")
sd_pop_i <- ggplotly(sd_pop, tooltip = "text")

# arrange them together
subplot(sd_gdp_i, sd_le_i, sd_pop_i, nrows = 3, titleY = TRUE) %>% 
  config(collaborate = FALSE, displaylogo = FALSE) %>% 
  hide_legend() %>% 
  highlight(selectize = TRUE, on = "plotly_click", off = "plotly_doubleclick") %>% 
  frameWidget(height = "600px")

```

<br>

---

## Searchable Data Tables

We can also use interactive data tables with search functionality and column sorting to allow users to quickly find the numbers they are looking for. Clicking on column headers will sort the data ascending or descending.


```{r}
fmrt <- formatter("span", 
  style = x ~ style(color = ifelse(x > 0, "green", ifelse(x < 0, "red", "black"))),
  x ~ icontext(ifelse(x > 0, "arrow-up", "arrow-down"), percent(x, digits = 1)))

mills <- scales::unit_format(scale = 1e-6, accuracy = .01, unit = "M")

tdat <- latest_figs %>%
  select(-continent) %>% 
  select(1:2, 5, 3, 6, 4, 7) %>% 
  mutate(pop = mills(pop))

ftbl <- formattable(tdat, list(
  gdpPercap_change = fmrt,
  lifeExp_change = fmrt,
  pop_change = fmrt
))

as.datatable(ftbl, rownames = FALSE, caption = "Latest Period Changes 2002-2007",
             colnames = c("Country", "GDP Per Capita", "+/-", "Life Expectancy", "+/-", "Population", "+/-"),
             options = list(columnDefs = list(list(className = 'dt-center', targets = c(1,3,5))))
                            #dom = 'ftip')
             ) %>% 
  formatCurrency(columns = 2) %>% 
  formatRound(columns = 4, digits = 1) %>% 
  frameWidget(height = "500px")
```

---

```{r}
p <- filtered_data %>% 
  filter(year == max(year)) %>% 
  ggplot(aes(gdpPercap, lifeExp, label = country)) +
  geom_point(aes(size = pop), fill = "SteelBlue", colour = "white", alpha = .7, pch = 21) +
  ggrepel::geom_text_repel(colour = "white", force = 3, segment.colour = "grey") +
  scale_size(range = c(2, 12)) +
  labs(x = "GDP per capita", y = "Life Expectancy",
       title = "Latest European Metrics", subtitle = "Year: {frame_time}",
       caption = "Source: Gapminder", size = "Population")
```

```{r}
p <- ggplot(filtered_data, aes(gdpPercap, lifeExp, label = country)) +
  geom_point(aes(size = pop), fill = "SteelBlue", colour = "white", alpha = .7, pch = 21) +
  ggrepel::geom_text_repel(colour = "white", force = 3, segment.colour = "grey",
                           max.iter = 12) +
  scale_size(range = c(2, 12)) +
  labs(x = "GDP per capita", y = "Life Expectancy",
       title = "Latest European Metrics", subtitle = "Year: {frame_time}",
       caption = "Source: Gapminder", size = "Population") +
  transition_time(as.integer(year))
p
```



We may want our report to keep an eye on a sepcific subset of the data. 

```{r}
indx <- filtered_data %>% 
  mutate(year = as.Date(paste0(year, "-01-01"))) %>% 
  group_by(country) %>% 
  arrange(year) %>% 
  mutate(gdpPercap_change = (gdpPercap / first(gdpPercap)) * 100,
         lifeExp_change = (lifeExp / first(lifeExp)) * 100,
         pop_change = (pop / first(pop)) * 100
         ) %>% 
  ungroup()

base_breaks <- function(n = 10){
    function(x) {
        axisTicks(log10(range(x, na.rm = TRUE)), log = TRUE, n = n)
    }
}

#highlight_countries <- c("United Kingdom", "Singapore", "Argentina", "Brazil", "India", "Ethiopia")

top_countries <- 
  indx %>% 
  filter(year == max(year)) %>% 
  top_n(5, gdpPercap_change) %>% 
  pull(country)

bottom_countries <- 
  indx %>% 
  filter(year == max(year)) %>% 
  top_n(-5, gdpPercap_change) %>% 
  pull(country)

p <- ggplot(indx, aes(year, gdpPercap_change, colour = country)) +
  geom_line(size = 1) +
  gghighlight(country %in% c(top_countries, bottom_countries)) +
  geom_point(aes(x = min(year), y = 100), colour = "black", size = 2) +
  #scale_y_continuous(trans = "log10", breaks = base_breaks(), labels = prettyNum) +
  labs(y = "Index (log10 scale)", 
       title = "Keeping Track - GDP Per Capita from Base Index", 
       subtitle = "Index 100 = Year 1952",
       caption = "Source: Gapminder")
p
```


```{r}
continent_summary <- 
  combined_data %>% 
  group_by(continent, year) %>% 
  summarise(gdpPercap = weighted.mean(gdpPercap, pop),
            lifeExp = weighted.mean(lifeExp, pop),
            pop = sum(pop)) %>% 
  gather(metric, value, 3:5) %>% 
  mutate(year = as.Date(glue("{year}-01-01")))
```


Making the switch to doing your data work with R can be daunting, but with the combination of <a href="https://www.rstudio.com/products/RStudio/" target="_blank">RStudio</a> as your 'integrated development environment', the <a href="https://www.tidyverse.org/" target="_blank">tidyverse packages</a> for data analysis, and <a href="https://rmarkdown.rstudio.com/" target="_blank">rmarkdown</a> for producing reports in just about any format you'd like (HTML, PDF, Word, PowerPoint, Dashboard, even entire websites like this one!), along with a really great and welcoming community of R users online, there has never been a better time to make the leap and start your journey on the path to data programming nirvana.
